import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import os
import discord
from discord.ext import commands
from dotenv import load_dotenv

# === í™˜ê²½ ë³€ìˆ˜ ë° ë´‡ ì„¤ì • ===
load_dotenv()
TOKEN = os.getenv("DISCORD_TOKEN")

intents = discord.Intents.default()
intents.message_content = True  # ë©”ì‹œì§€ ë‚´ìš© ì ‘ê·¼ í™œì„±í™”
intents.members = True          # ë©¤ë²„ ì •ë³´ ì ‘ê·¼ í™œì„±í™”
bot = commands.Bot(command_prefix="!", intents=intents)

# === URL ë° ì—­í• /ì±„ë„ ë§¤í•‘ ì„¤ì • ===
role_emoji_map = {
    "ğŸ“š": {
        "role": "ì „ë‚¨ëŒ€í•™êµ ê³µì§€", 
        "channel_id": int(os.getenv("CHANNEL_ID_1")), 
        "url": "https://www.jnu.ac.kr/WebApp/web/HOM/COM/Board/board.aspx?boardID=5&bbsMode=list&cate=0",
        "multi_page": True  # ì „ë‚¨ëŒ€í•™êµ ê³µì§€ëŠ” ë‹¤ì¤‘ í˜ì´ì§€ ì²˜ë¦¬ í•„ìš”
    },
    "ğŸ–¥ï¸": {
        "role": "ê³µê³¼ëŒ€í•™ ê³µì§€", 
        "channel_id": int(os.getenv("CHANNEL_ID_2")), 
        "url": "https://eng.jnu.ac.kr/eng/7343/subview.do",
        "multi_page": False
    },
    "ğŸ’»": {
        "role": "ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼ ê³µì§€", 
        "channel_id": int(os.getenv("CHANNEL_ID_3")), 
        "url": "https://sw.jnu.ac.kr/sw/8250/subview.do",
        "multi_page": False
    },
    "âš¡": {
        "role": "ì „ìì»´í“¨í„°ê³µí•™ë¶€ ê³µì§€", 
        "channel_id": int(os.getenv("CHANNEL_ID_4")), 
        "url": "https://eceng.jnu.ac.kr/eceng/20079/subview.do",
        "multi_page": False
    },
    "ğŸ¤–": {
        "role": "AIìœµí•©ëŒ€í•™ ê³µì§€", 
        "channel_id": int(os.getenv("CHANNEL_ID_5")), 
        "url": "https://cvg.jnu.ac.kr/cvg/3608/subview.do",
        "multi_page": False
    },
    "ğŸ§ ": {
        "role": "ì¸ê³µì§€ëŠ¥í•™ë¶€ ê³µì§€", 
        "channel_id": int(os.getenv("CHANNEL_ID_6")), 
        "url": "https://aisw.jnu.ac.kr/aisw/518/subview.do",
        "multi_page": False
    }
}

# === ê³µì§€ì‚¬í•­ ê´€ë¦¬ ê´€ë ¨ ë³€ìˆ˜ ===
txt_file = "crawl.txt"
today = datetime.now()
threshold_date = today - timedelta(days=2)

# === ê³µì§€ì‚¬í•­ ì²˜ë¦¬ í•¨ìˆ˜ ===
def load_existing_notices(file_path):
    if not os.path.exists(file_path):
        return set()
    with open(file_path, "r", encoding="utf-8") as file:
        return set(line.strip() for line in file)

def save_new_notices(file_path, notices):
    with open(file_path, "a", encoding="utf-8") as file:
        for notice in notices:
            file.write(f"{notice['date']}|{notice['source']}|{notice['title']}\n")

def fetch_notices(url, source, existing_notices):
    response = requests.get(url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, 'html.parser')
    notices = []
    tbody = soup.find('tbody')
    rows = tbody.find_all('tr')

    new_notices = []

    for row in rows:
        date_td = row.find('td', class_='td-date')
        title_td = row.find('td', class_='td-subject')
        link_tag = title_td.find('a') if title_td else None

        if date_td and title_td and link_tag:
            date_text = date_td.text.strip()
            title_parts = [part.strip() for part in title_td.stripped_strings]
            title = " ".join(title_parts)
            base_url = "/".join(url.split('/')[:3])  # Extract base URL (e.g., https://sw.jnu.ac.kr)
            link = base_url + link_tag['href']

            # ë‚ ì§œ íŒŒì‹±
            try:
                notice_date = datetime.strptime(date_text, "%Y.%m.%d")
            except ValueError:
                continue

            # ë‚ ì§œ ë¹„êµ í›„ í•„í„°ë§
            if threshold_date <= notice_date <= today:
                notice_key = f"{date_text}|{source}|{title}"
                if notice_key not in existing_notices:
                    new_notices.append({
                        'title': title,
                        'date': date_text,
                        'link': link,
                        'source': source
                    })
                    notices.append(notice_key)

    return new_notices

def fetch_notices_multi_page(base_url, source, existing_notices, max_pages=3):
    new_notices = []

    for page in range(1, max_pages + 1):
        url = f"{base_url}&page={page}"
        response = requests.get(url)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')
        tbody = soup.find('tbody')
        if not tbody:
            print(f"tbody íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URL: {url}")
            continue

        rows = tbody.find_all('tr')

        for row in rows:
            # ë‚ ì§œ ë° ì œëª© ì°¾ê¸°
            date_td = row.find_all('td', class_='under')[-2]
            title_td = row.find('td', class_='title')
            link_tag = title_td.find('a') if title_td else None

            if date_td and title_td and link_tag:
                date_text = date_td.text.strip()
                title_parts = [part.strip() for part in title_td.stripped_strings]
                title = " ".join(title_parts)
                link = "https://www.jnu.ac.kr" + link_tag['href']
                
                # ë‚ ì§œ íŒŒì‹±
                try:
                    notice_date = datetime.strptime(date_text, "%Y-%m-%d")
                except ValueError:
                    continue

                # ë‚ ì§œ ë¹„êµ í›„ í•„í„°ë§
                if threshold_date <= notice_date <= today:
                    notice_key = f"{date_text}|{source}|{title}"
                    if notice_key not in existing_notices:
                        new_notices.append({
                            'title': title,
                            'date': date_text,
                            'link': link,
                            'source': source
                        })

    return new_notices

# === ë””ìŠ¤ì½”ë“œ ë´‡ ì´ë²¤íŠ¸ ë° ëª…ë ¹ì–´ ===
@bot.event
async def on_ready():
    print(f"Logged in as {bot.user}")

@bot.event
async def on_reaction_add(reaction, user):
    """ì´ëª¨ì§€ í´ë¦­ ì‹œ ì—­í•  ë¶€ì—¬"""
    if user.bot:
        return

    emoji = str(reaction.emoji)
    data = role_emoji_map.get(emoji)
    if data:
        guild = reaction.message.guild
        role = discord.utils.get(guild.roles, name=data["role"])
        if role:
            await user.add_roles(role)
            # await user.send(f"{data['role']} ì—­í• ì´ ë¶€ì—¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
@bot.event
async def on_reaction_remove(reaction, user):
    """ì´ëª¨ì§€ ì œê±° ì‹œ ì—­í•  ì œê±°"""
    if user.bot:
        return

    emoji = str(reaction.emoji)
    data = role_emoji_map.get(emoji)
    if data:
        guild = reaction.message.guild
        role = discord.utils.get(guild.roles, name=data["role"])
        if role:
            await user.remove_roles(role)
            # await user.send(f"{data['role']} ì—­í• ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤!")

# @bot.command()
# async def ê³µì§€(ctx):
#     """ëª¨ë“  ì‚¬ì´íŠ¸ì˜ ê³µì§€ì‚¬í•­ ì¶œë ¥"""
#     existing_notices = load_existing_notices(txt_file)
#     all_new_notices = []

#     for emoji, data in role_emoji_map.items():
#         if data.get("multi_page"):
#             new_notices = fetch_notices_multi_page(data["url"], data["role"], existing_notices)
#         else:
#             new_notices = fetch_notices(data["url"], data["role"], existing_notices)
#         all_new_notices.extend(new_notices)

#     if all_new_notices:
#         save_new_notices(txt_file, all_new_notices)
#         for notice in all_new_notices:
#             await ctx.send(f"[{notice['source']}] {notice['title']}\n{notice['link']}")
#     else:
#         await ctx.send("ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤!")

@bot.command()
async def ê³µì§€(ctx):
    """í•´ë‹¹ ì±„ë„ì— ì—°ê²°ëœ ì‚¬ì´íŠ¸ì˜ ê³µì§€ì‚¬í•­ë§Œ ì¶œë ¥"""
    channel_id = ctx.channel.id
    data = next((data for data in role_emoji_map.values() if data["channel_id"] == channel_id), None)

    if not data:
        await ctx.send("ì´ ì±„ë„ì— ì—°ê²°ëœ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤!")
        return

    existing_notices = load_existing_notices(txt_file)
    if data.get("multi_page"):
        new_notices = fetch_notices_multi_page(data["url"], data["role"], existing_notices)
    else:
        new_notices = fetch_notices(data["url"], data["role"], existing_notices)

    if new_notices:
        save_new_notices(txt_file, new_notices)
        for notice in new_notices:
            await ctx.send(f"[{notice['source']}] {notice['title']}\n{notice['link']}")
    else:
        await ctx.send("ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤!")

# === ë´‡ ì‹¤í–‰ ===
bot.run(TOKEN)